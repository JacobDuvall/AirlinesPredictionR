---
title: "Flight Delays January 2015"
author: "Jacob Duvall"
date: "7/10/2019"
output:
  html_document:
    toc: true
    keep_md: true
---

# Clean Data

```{r}
origData = read.csv2('C:\\Users\\jdduval1\\Desktop\\814981452_T_ONTIME_REPORTING.csv', sep=",", header=TRUE, stringsAsFactors=FALSE)
```

```{r}
nrow(origData)
```

```{r}
# reduce number of rows
airports = c('ATL', 'LAX', 'ORD', 'DFW', 'JFK', 'SFO', 'CLT', 'LAS', 'PHX')
origData = subset(origData, DEST %in% airports & ORIGIN %in% airports)
```

```{r}
nrow(origData)
```

```{r}
head(origData,2)
# x column has no value
```

```{r}
# checking that x has no value here either
tail(origData, 2)
```

```{r}
# remove x column
origData$X = NULL
head(origData, 2)
```

```{r}
# check for correlated columns that might skew the results - value close to 1 is a correlation
cor(origData[c("ORIGIN_AIRPORT_ID", "ORIGIN_AIRPORT_SEQ_ID")])
cor(origData[c("DEST_AIRPORT_SEQ_ID", "DEST_AIRPORT_ID")])
```

```{r}
# drop correlated columns
origData$ORIGIN_AIRPORT_SEQ_ID = NULL
origData$DEST_AIRPORT_SEQ_ID = NULL
```

```{r}
# check if OP_CARRIER and OP_UNIQUE_CARRIER are different 
mismatched = origData[origData$OP_CARRIER != origData$OP_UNIQUE_CARRIER,]
nrow(mismatched)
# these are the same
```

```{r}
# drop correlated column
origData$OP_UNIQUE_CARRIER = NULL
head(origData,2)
```

# Mold Data

```{r}
# create new dataframe where origData is modified to remove empty rows in ARR_DEL15 and DEP_DEL15
onTimeData = origData[!is.na(origData$ARR_DEL15) & origData$ARR_DEL15 != "" & !is.na(origData$DEP_DEL15) & origData$DEP_DEL15 != "",]
```

```{r}
# check the number of rows removed
nrow(origData)
nrow(onTimeData)
```

```{r}
# change the data type of columns DISTANCE, CANCELLED, DIVERTED from chr to int
onTimeData$DISTANCE = as.integer(onTimeData$DISTANCE)
onTimeData$CANCELLED = as.integer(onTimeData$CANCELLED)
onTimeData$DIVERTED = as.integer(onTimeData$DIVERTED)
```

```{r}
# change the data type of columns DEP_DEL15, ARR_DEL15, DEST_AIRPORT_ID, ORIGIN_AIRPORT_ID
# DAY_OF_WEEK, DEST, ORIGIN, DEP_TIME_BLK, CARRIER to Factor
onTimeData$ARR_DEL15 = as.factor(onTimeData$ARR_DEL15)
onTimeData$DEP_DEL15 = as.factor(onTimeData$DEP_DEL15)
onTimeData$DEST_AIRPORT_ID = as.factor(onTimeData$DEST_AIRPORT_ID)
onTimeData$ORIGIN_AIRPORT_ID = as.factor(onTimeData$DAY_OF_WEEK)
onTimeData$DAY_OF_WEEK = as.factor(onTimeData$DEP_DEL15)
onTimeData$DEST = as.factor(onTimeData$DEST)
onTimeData$ORIGIN = as.factor(onTimeData$ORIGIN)
onTimeData$DEP_TIME_BLK = as.factor(onTimeData$DEP_TIME_BLK)
onTimeData$OP_CARRIER = as.factor(onTimeData$OP_CARRIER)
```

```{r}
# check number of delays vs number of non-delays
tapply(onTimeData$ARR_DEL15, onTimeData$ARR_DEL15, length)
(6460 / (25664 + 6460))
# can reasonably train model with 20% rate 
```

# Training the Model

```{r message=FALSE}
library(caret)
```

```{r}
set.seed(122515)
```


```{r}
# The important columns to base training data 
featureCols = c("ARR_DEL15", "DAY_OF_WEEK", "OP_CARRIER", "DEST", "ORIGIN", "DEP_TIME_BLK")
onTimeDataFiltered = onTimeData[,featureCols]
```

```{r}
# split into training and testing data - 70% split among ARR_DEL15
inTrainRows = createDataPartition(onTimeDataFiltered$ARR_DEL15, p=0.70, list=FALSE)
```

```{r}
head(inTrainRows, 10)
```

```{r}
# set up training and test data based on the row split
trainDataFiltered = onTimeDataFiltered[inTrainRows,]
testDataFiltered = onTimeDataFiltered[-inTrainRows,]
```

```{r}
# check for 70% split
nrow(trainDataFiltered)/(nrow(testDataFiltered) + nrow(trainDataFiltered))
```

```{r}
# check for 30% split
nrow(testDataFiltered)/(nrow(testDataFiltered) + nrow(trainDataFiltered))
```

```{r}
# train with LOGISTIC REGRESSION using all columns other than ARR_DEL15
logisticRegModel = train(ARR_DEL15 ~ ., data=trainDataFiltered, method="glm", family = "binomial")
```

```{r}
logisticRegModel
```

# Testing the Model Accuracy

```{r}
# predict using the model and the test data
logRegPrediction = predict(logisticRegModel, testDataFiltered)
```

```{r}
# create a confusion matrix
logRegConfMat = confusionMatrix(logRegPrediction, testDataFiltered[, "ARR_DEL15"])
```

```{r}
logRegConfMat
# great results!
```
